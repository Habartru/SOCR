# SuperOCR Configuration File
# Скопируйте этот файл в local.env и настройте под свои нужды

# LLM Settings
LLM_PROVIDER=lm_studio
# Возможные значения: lm_studio, openai

# LM Studio настройки
LM_STUDIO_ENDPOINT=http://localhost:1234
LM_STUDIO_MODEL=llama-3.1-8b-instruct
LM_STUDIO_TIMEOUT=180

# OpenAI настройки (если используется)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_ENDPOINT=https://api.openai.com

# OCR настройки
OCR_THREADS=4
# Количество потоков для OCR обработки

# LLM настройки
LLM_THREADS=2
# Количество потоков для LLM обработки

# Настройки автоповтора
AUTO_RETRY_ENABLED=true
MAX_RETRY_ATTEMPTS=3

# Пути (опционально)
# INPUT_FOLDER=/path/to/input/pdfs
# OUTPUT_FOLDER=/path/to/output/results

# Логирование
LOG_LEVEL=INFO
# Возможные значения: DEBUG, INFO, WARNING, ERROR

# GPU настройки
CUDA_VISIBLE_DEVICES=0
# Указать номер GPU для использования (0, 1, 2...) или -1 для CPU

# Дополнительные настройки
MAX_TEXT_LENGTH=8000
# Максимальная длина текста для отправки в LLM

TRUNCATE_STRATEGY=smart
# Стратегия усечения: smart, simple, none
